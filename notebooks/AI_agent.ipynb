{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b93f30a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import os\n",
    "# import asyncio\n",
    "# import pickle\n",
    "# import pandas as pd\n",
    "# import streamlit as st\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# # LangChain integrations\n",
    "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "# from langchain.agents import initialize_agent, Tool\n",
    "\n",
    "# # --------------------------\n",
    "# # Setup\n",
    "# # --------------------------\n",
    "# load_dotenv()\n",
    "# st.title(\"ðŸ“Š Marketing Assistant with Churn Prediction\")\n",
    "\n",
    "# google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "# chat_model_name = \"models/gemini-2.0-flash-lite-preview\"\n",
    "\n",
    "# # Ensure event loop exists\n",
    "# try:\n",
    "#     asyncio.get_running_loop()\n",
    "# except RuntimeError:\n",
    "#     asyncio.set_event_loop(asyncio.new_event_loop())\n",
    "\n",
    "# # --------------------------\n",
    "# # Load your churn model\n",
    "# # --------------------------\n",
    "# with open(r\"D:\\ITI\\1_etisalt\\Etisalat\\churn\\models\\churn.pkl\", \"rb\") as f:\n",
    "#     churn_model = pickle.load(f)\n",
    "\n",
    "# # Define churn prediction tool\n",
    "# def predict_churn(data: dict) -> str:\n",
    "#     \"\"\"\n",
    "#     Takes a dict of customer features and returns churn prediction.\n",
    "#     Expected fields:\n",
    "#     CustomerId, Gender, Senior_Citizen, Is_Married, Dependents, tenure,\n",
    "#     Phone_Service, Dual, Internet_Service, Online_Security, Online_Backup,\n",
    "#     Device_Protection, Tech_Support, Streaming_TV, Streaming_Movies,\n",
    "#     Contract, Paperless_Billing, Payment_Method, Monthly_Charges, Total_Charges\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         df = pd.DataFrame([data])\n",
    "#         pred = churn_model.predict(df)[0]\n",
    "#         prob = None\n",
    "#         if hasattr(churn_model, \"predict_proba\"):\n",
    "#             prob = churn_model.predict_proba(df)[0].max()\n",
    "\n",
    "#         if prob:\n",
    "#             return f\"Prediction: {pred} (confidence: {prob:.2f})\"\n",
    "#         return f\"Prediction: {pred}\"\n",
    "#     except Exception as e:\n",
    "#         return f\"âŒ Error making prediction: {str(e)}\"\n",
    "\n",
    "# # Wrap model as tool\n",
    "# tools = [\n",
    "#     Tool(\n",
    "#         name=\"Churn Predictor\",\n",
    "#         func=predict_churn,\n",
    "#         description=(\n",
    "#             \"Use this tool to predict if a customer will churn. \"\n",
    "#             \"Provide customer details as a JSON dict with keys such as \"\n",
    "#             \"Gender, Senior_Citizen, Is_Married, Dependents, tenure, \"\n",
    "#             \"Phone_Service, Internet_Service, Contract, Monthly_Charges, \"\n",
    "#             \"Total_Charges, etc.\"\n",
    "#         )\n",
    "#     )\n",
    "# ]\n",
    "\n",
    "# # --------------------------\n",
    "# # Session state for messages\n",
    "# # --------------------------\n",
    "# if \"messages\" not in st.session_state:\n",
    "#     st.session_state.messages = []\n",
    "#     st.session_state.messages.append(SystemMessage(\n",
    "#         \"You are a marketing assistant. \"\n",
    "#         \"If the user asks about churn prediction, use the Churn Predictor tool. \"\n",
    "#         \"Otherwise, answer normally.\"\n",
    "#     ))\n",
    "\n",
    "# # --------------------------\n",
    "# # Display previous messages\n",
    "# # --------------------------\n",
    "# for message in st.session_state.messages:\n",
    "#     if isinstance(message, HumanMessage):\n",
    "#         with st.chat_message(\"user\"):\n",
    "#             st.markdown(message.content)\n",
    "#     elif isinstance(message, AIMessage):\n",
    "#         with st.chat_message(\"assistant\"):\n",
    "#             st.markdown(message.content)\n",
    "\n",
    "# # --------------------------\n",
    "# # Chat input\n",
    "# # --------------------------\n",
    "# prompt = st.chat_input(\"Ask about churn or marketing insights...\")\n",
    "\n",
    "# if prompt:\n",
    "#     # Add user input\n",
    "#     with st.chat_message(\"user\"):\n",
    "#         st.markdown(prompt)\n",
    "#     st.session_state.messages.append(HumanMessage(prompt))\n",
    "\n",
    "#     # Create LLM + Agent\n",
    "#     model_llm = ChatGoogleGenerativeAI(\n",
    "#         model=chat_model_name,\n",
    "#         temperature=0,\n",
    "#         google_api_key=google_api_key\n",
    "#     )\n",
    "\n",
    "#     agent = initialize_agent(\n",
    "#         tools=tools,\n",
    "#         llm=model_llm,\n",
    "#         agent=\"zero-shot-react-description\",\n",
    "#         verbose=True\n",
    "#     )\n",
    "\n",
    "#     # Run agent\n",
    "#     result = agent.run(prompt)\n",
    "\n",
    "#     # Display response\n",
    "#     with st.chat_message(\"assistant\"):\n",
    "#         st.markdown(result)\n",
    "#     st.session_state.messages.append(AIMessage(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9315481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f42dc3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.agents import initialize_agent, Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f2b4edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "chat_model_name = \"models/gemini-2.0-flash-lite-preview\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1047c98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure event loop exists\n",
    "try:\n",
    "    asyncio.get_running_loop()\n",
    "except RuntimeError:\n",
    "    asyncio.set_event_loop(asyncio.new_event_loop())\n",
    "\n",
    "\n",
    "with open(\"../models/churn.pkl\", \"rb\") as f:\n",
    "    churn_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "33901691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Senior_Citizen' 'Is_Married' 'Dependents' 'tenure' 'Internet_Service'\n",
      " 'Online_Security' 'Online_Backup' 'Device_Protection' 'Tech_Support'\n",
      " 'Streaming_TV' 'Streaming_Movies' 'Contract' 'Paperless_Billing'\n",
      " 'Payment_Method' 'Monthly_Charges' 'Total_Charges']\n"
     ]
    }
   ],
   "source": [
    "print(churn_model.named_steps[\"preprocessor\"].feature_names_in_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb353a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_churn(data: dict) -> str:\n",
    "    \"\"\"\n",
    "    Takes a dict of customer features and returns churn prediction\n",
    "    with confidence score in a descriptive sentence.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        EXPECTED_COLS = [\n",
    "            'Senior_Citizen', 'Is_Married', 'Dependents', 'tenure',\n",
    "            'Internet_Service', 'Online_Security', 'Online_Backup',\n",
    "            'Device_Protection', 'Tech_Support', 'Streaming_TV',\n",
    "            'Streaming_Movies', 'Contract', 'Paperless_Billing',\n",
    "            'Payment_Method', 'Monthly_Charges', 'Total_Charges'\n",
    "        ]\n",
    "\n",
    "        # Convert dict -> DataFrame\n",
    "        one_raw = pd.DataFrame([data])\n",
    "\n",
    "        # Ensure all expected columns exist\n",
    "        for col in EXPECTED_COLS:\n",
    "            if col not in one_raw.columns:\n",
    "                one_raw[col] = None\n",
    "\n",
    "        one_raw = one_raw[EXPECTED_COLS]\n",
    "        one_raw.columns = one_raw.columns.astype(str)\n",
    "\n",
    "        # Fix numeric columns\n",
    "        one_raw[\"Senior_Citizen\"] = pd.to_numeric(one_raw[\"Senior_Citizen\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "        one_raw[\"tenure\"] = pd.to_numeric(one_raw[\"tenure\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "        one_raw[\"Monthly_Charges\"] = pd.to_numeric(one_raw[\"Monthly_Charges\"], errors=\"coerce\").fillna(0.0)\n",
    "        one_raw[\"Total_Charges\"] = pd.to_numeric(one_raw[\"Total_Charges\"], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "        # Predict\n",
    "        pred = churn_model.predict(one_raw)[0]\n",
    "\n",
    "        prob = None\n",
    "        if hasattr(churn_model, \"predict_proba\"):\n",
    "            proba = churn_model.predict_proba(one_raw)[0]\n",
    "            prob = proba[pred]   # probability of predicted class\n",
    "\n",
    "        # Map back 0/1 to Yes/No\n",
    "        target_map = {0: \"No\", 1: \"Yes\"}\n",
    "        pred_label = target_map.get(pred, str(pred))\n",
    "\n",
    "        if prob is not None:\n",
    "            return f\"âœ… After running the churn prediction model, the prediction is: **{pred_label}** with a confidence of **{prob:.2f}**.\"\n",
    "        else:\n",
    "            return f\"âœ… After running the churn prediction model, the prediction is: **{pred_label}**.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"âŒ Error making prediction: {str(e)}\"\n",
    "\n",
    "\n",
    "# def predict_churn(data: dict) -> str:\n",
    "#     \"\"\"\n",
    "#     Takes a dict of customer features and returns churn prediction.\n",
    "#     Expected fields:\n",
    "#     'Senior_Citizen', 'Is_Married', 'Dependents', 'tenure',\n",
    "#     'Internet_Service', 'Online_Security', 'Online_Backup',\n",
    "#     'Device_Protection', 'Tech_Support', 'Streaming_TV',\n",
    "#     'Streaming_Movies', 'Contract', 'Paperless_Billing',\n",
    "#     'Payment_Method', 'Monthly_Charges', 'Total_Charges'\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         # Expected schema\n",
    "#         EXPECTED_COLS = [\n",
    "#             'Senior_Citizen', 'Is_Married', 'Dependents', 'tenure',\n",
    "#             'Internet_Service', 'Online_Security', 'Online_Backup',\n",
    "#             'Device_Protection', 'Tech_Support', 'Streaming_TV',\n",
    "#             'Streaming_Movies', 'Contract', 'Paperless_Billing',\n",
    "#             'Payment_Method', 'Monthly_Charges', 'Total_Charges'\n",
    "#         ]\n",
    "\n",
    "#         # Convert dict -> DataFrame\n",
    "#         one_raw = pd.DataFrame([data])\n",
    "\n",
    "#         # Ensure all expected columns exist\n",
    "#         for col in EXPECTED_COLS:\n",
    "#             if col not in one_raw.columns:\n",
    "#                 one_raw[col] = None  # placeholder\n",
    "\n",
    "#         # Keep only expected cols, in correct order\n",
    "#         one_raw = one_raw[EXPECTED_COLS]\n",
    "\n",
    "#         # Make sure all column names are strings\n",
    "#         one_raw.columns = one_raw.columns.astype(str)\n",
    "\n",
    "#         # Fix numeric columns\n",
    "#         one_raw[\"Senior_Citizen\"] = pd.to_numeric(one_raw[\"Senior_Citizen\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "#         one_raw[\"tenure\"] = pd.to_numeric(one_raw[\"tenure\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "#         one_raw[\"Monthly_Charges\"] = pd.to_numeric(one_raw[\"Monthly_Charges\"], errors=\"coerce\").fillna(0.0)\n",
    "#         one_raw[\"Total_Charges\"] = pd.to_numeric(one_raw[\"Total_Charges\"], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "#         # Predict\n",
    "#         pred = churn_model.predict(one_raw)[0]\n",
    "#         prob = None\n",
    "#         if hasattr(churn_model, \"predict_proba\"):\n",
    "#             prob = churn_model.predict_proba(one_raw)[0].max()\n",
    "\n",
    "#         # Map back 0/1 to Yes/No\n",
    "#         target_map = {0: \"No\", 1: \"Yes\"}\n",
    "#         pred_label = target_map.get(pred, pred)\n",
    "\n",
    "#         if prob is not None:\n",
    "#             return f\"Prediction: {pred_label} (confidence: {prob:.2f})\"\n",
    "#         return f\"Prediction: {pred_label}\"\n",
    "\n",
    "#     except Exception as e:\n",
    "#         return f\"âŒ Error making prediction: {str(e)}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d5f77233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… After running the churn prediction model, the prediction is: **No** with a confidence of **0.62**.\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "  \"Senior_Citizen\": 0,\n",
    "  \"Is_Married\": \"Yes\",\n",
    "  \"Dependents\": \"No\",\n",
    "  \"tenure\": 5,\n",
    "  \"Internet_Service\": \"DSL\",\n",
    "  \"Online_Security\": \"No\",\n",
    "  \"Online_Backup\": \"Yes\",\n",
    "  \"Device_Protection\": \"No\",\n",
    "  \"Tech_Support\": \"No\",\n",
    "  \"Streaming_TV\": \"Yes\",\n",
    "  \"Streaming_Movies\": \"No\",\n",
    "  \"Contract\": \"Month-to-month\",\n",
    "  \"Paperless_Billing\": \"Yes\",\n",
    "  \"Payment_Method\": \"Electronic check\",\n",
    "  \"Monthly_Charges\": 75.0,\n",
    "  \"Total_Charges\": 350.0,\n",
    "}\n",
    "\n",
    "\n",
    "print(predict_churn(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "340f4785",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_predic_tool = Tool(\n",
    "    name=\"Churn Predictor\",\n",
    "    func=predict_churn,\n",
    "    description=(\n",
    "        \"Predicts whether a customer is likely to churn (leave the service). \"\n",
    "        \"You must provide customer details as a JSON dictionary with the following keys: \"\n",
    "        \"Senior_Citizen (0 or 1), Is_Married (Yes/No), Dependents (Yes/No), tenure (numeric), \"\n",
    "        \"Internet_Service (No/DSL/Fiber optic), Online_Security (Yes/No), Online_Backup (Yes/No), \"\n",
    "        \"Device_Protection (Yes/No), Tech_Support (Yes/No), Streaming_TV (Yes/No), \"\n",
    "        \"Streaming_Movies (Yes/No), Contract (Month-to-month/One year/Two year), \"\n",
    "        \"Paperless_Billing (Yes/No), Payment_Method (Electronic check/Mailed check/Bank transfer (automatic)/Credit card (automatic)), \"\n",
    "        \"Monthly_Charges (numeric), and Total_Charges (numeric).\"\n",
    "    )\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cfc6ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    churn_predic_tool,\n",
    "    # stats_tool\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a6e6879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_llm = ChatGoogleGenerativeAI(\n",
    "    model=chat_model_name,\n",
    "    temperature=0,\n",
    "    google_api_key=google_api_key\n",
    ")\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=model_llm,\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "174b67f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to use the Churn Predictor tool to predict churn for the given customer data.\n",
      "Action: Churn Predictor\n",
      "Action Input: {\"Senior_Citizen\": 0, \"Is_Married\": \"Yes\", \"Dependents\": \"No\", \"tenure\": 5, \"Internet_Service\": \"DSL\", \"Online_Security\": \"No\", \"Online_Backup\": \"Yes\", \"Device_Protection\": \"No\", \"Tech_Support\": \"No\", \"Streaming_TV\": \"Yes\", \"Streaming_Movies\": \"No\", \"Contract\": \"Month-to-month\", \"Paperless_Billing\": \"Yes\", \"Payment_Method\": \"Electronic check\", \"Monthly_Charges\": 75, \"Total_Charges\": 350}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mâœ… After running the churn prediction model, the prediction is: **Yes** with a confidence of **0.51**.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the churn prediction.\n",
      "Final Answer: Yes\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Assistant: Yes\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"Predict churn for the following customer: {\n",
    "  \"Senior_Citizen\": 0,\n",
    "  \"Is_Married\": \"Yes\",\n",
    "  \"Dependents\": \"No\",\n",
    "  \"tenure\": 5,\n",
    "  \"Internet_Service\": \"DSL\",\n",
    "  \"Online_Security\": \"No\",\n",
    "  \"Online_Backup\": \"Yes\",\n",
    "  \"Device_Protection\": \"No\",\n",
    "  \"Tech_Support\": \"No\",\n",
    "  \"Streaming_TV\": \"Yes\",\n",
    "  \"Streaming_Movies\": \"No\",\n",
    "  \"Contract\": \"Month-to-month\",\n",
    "  \"Paperless_Billing\": \"Yes\",\n",
    "  \"Payment_Method\": \"Electronic check\",\n",
    "  \"Monthly_Charges\": 75,\n",
    "  \"Total_Charges\": 350\n",
    "}\"\"\"\n",
    "\n",
    "result = agent.run(query)\n",
    "print(\"Assistant:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "307c3a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0 (confidence: 0.62)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "one_raw = pd.DataFrame([data])\n",
    "pred = churn_model.predict(one_raw)[0]\n",
    "\n",
    "prob = churn_model.predict_proba(one_raw)[0].max()\n",
    "\n",
    "print(f\"Prediction: {pred} (confidence: {prob:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8f6d7701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Senior_Citizen' 'Is_Married' 'Dependents' 'tenure' 'Internet_Service'\n",
      " 'Online_Security' 'Online_Backup' 'Device_Protection' 'Tech_Support'\n",
      " 'Streaming_TV' 'Streaming_Movies' 'Contract' 'Paperless_Billing'\n",
      " 'Payment_Method' 'Monthly_Charges' 'Total_Charges']\n"
     ]
    }
   ],
   "source": [
    "print(churn_model.named_steps[\"preprocessor\"].feature_names_in_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79a3bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0f81e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2a4263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b51a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5351bc5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "churn (3.10.17)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
