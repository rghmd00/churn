{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b93f30a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import os\n",
    "# import asyncio\n",
    "# import pickle\n",
    "# import pandas as pd\n",
    "# import streamlit as st\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# # LangChain integrations\n",
    "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "# from langchain.agents import initialize_agent, Tool\n",
    "\n",
    "# # --------------------------\n",
    "# # Setup\n",
    "# # --------------------------\n",
    "# load_dotenv()\n",
    "# st.title(\"ðŸ“Š Marketing Assistant with Churn Prediction\")\n",
    "\n",
    "# google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "# chat_model_name = \"models/gemini-2.0-flash-lite-preview\"\n",
    "\n",
    "# # Ensure event loop exists\n",
    "# try:\n",
    "#     asyncio.get_running_loop()\n",
    "# except RuntimeError:\n",
    "#     asyncio.set_event_loop(asyncio.new_event_loop())\n",
    "\n",
    "# # --------------------------\n",
    "# # Load your churn model\n",
    "# # --------------------------\n",
    "# with open(r\"D:\\ITI\\1_etisalt\\Etisalat\\churn\\models\\churn.pkl\", \"rb\") as f:\n",
    "#     churn_model = pickle.load(f)\n",
    "\n",
    "# # Define churn prediction tool\n",
    "# def predict_churn(data: dict) -> str:\n",
    "#     \"\"\"\n",
    "#     Takes a dict of customer features and returns churn prediction.\n",
    "#     Expected fields:\n",
    "#     CustomerId, Gender, Senior_Citizen, Is_Married, Dependents, tenure,\n",
    "#     Phone_Service, Dual, Internet_Service, Online_Security, Online_Backup,\n",
    "#     Device_Protection, Tech_Support, Streaming_TV, Streaming_Movies,\n",
    "#     Contract, Paperless_Billing, Payment_Method, Monthly_Charges, Total_Charges\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         df = pd.DataFrame([data])\n",
    "#         pred = churn_model.predict(df)[0]\n",
    "#         prob = None\n",
    "#         if hasattr(churn_model, \"predict_proba\"):\n",
    "#             prob = churn_model.predict_proba(df)[0].max()\n",
    "\n",
    "#         if prob:\n",
    "#             return f\"Prediction: {pred} (confidence: {prob:.2f})\"\n",
    "#         return f\"Prediction: {pred}\"\n",
    "#     except Exception as e:\n",
    "#         return f\"âŒ Error making prediction: {str(e)}\"\n",
    "\n",
    "# # Wrap model as tool\n",
    "# tools = [\n",
    "#     Tool(\n",
    "#         name=\"Churn Predictor\",\n",
    "#         func=predict_churn,\n",
    "#         description=(\n",
    "#             \"Use this tool to predict if a customer will churn. \"\n",
    "#             \"Provide customer details as a JSON dict with keys such as \"\n",
    "#             \"Gender, Senior_Citizen, Is_Married, Dependents, tenure, \"\n",
    "#             \"Phone_Service, Internet_Service, Contract, Monthly_Charges, \"\n",
    "#             \"Total_Charges, etc.\"\n",
    "#         )\n",
    "#     )\n",
    "# ]\n",
    "\n",
    "# # --------------------------\n",
    "# # Session state for messages\n",
    "# # --------------------------\n",
    "# if \"messages\" not in st.session_state:\n",
    "#     st.session_state.messages = []\n",
    "#     st.session_state.messages.append(SystemMessage(\n",
    "#         \"You are a marketing assistant. \"\n",
    "#         \"If the user asks about churn prediction, use the Churn Predictor tool. \"\n",
    "#         \"Otherwise, answer normally.\"\n",
    "#     ))\n",
    "\n",
    "# # --------------------------\n",
    "# # Display previous messages\n",
    "# # --------------------------\n",
    "# for message in st.session_state.messages:\n",
    "#     if isinstance(message, HumanMessage):\n",
    "#         with st.chat_message(\"user\"):\n",
    "#             st.markdown(message.content)\n",
    "#     elif isinstance(message, AIMessage):\n",
    "#         with st.chat_message(\"assistant\"):\n",
    "#             st.markdown(message.content)\n",
    "\n",
    "# # --------------------------\n",
    "# # Chat input\n",
    "# # --------------------------\n",
    "# prompt = st.chat_input(\"Ask about churn or marketing insights...\")\n",
    "\n",
    "# if prompt:\n",
    "#     # Add user input\n",
    "#     with st.chat_message(\"user\"):\n",
    "#         st.markdown(prompt)\n",
    "#     st.session_state.messages.append(HumanMessage(prompt))\n",
    "\n",
    "#     # Create LLM + Agent\n",
    "#     model_llm = ChatGoogleGenerativeAI(\n",
    "#         model=chat_model_name,\n",
    "#         temperature=0,\n",
    "#         google_api_key=google_api_key\n",
    "#     )\n",
    "\n",
    "#     agent = initialize_agent(\n",
    "#         tools=tools,\n",
    "#         llm=model_llm,\n",
    "#         agent=\"zero-shot-react-description\",\n",
    "#         verbose=True\n",
    "#     )\n",
    "\n",
    "#     # Run agent\n",
    "#     result = agent.run(prompt)\n",
    "\n",
    "#     # Display response\n",
    "#     with st.chat_message(\"assistant\"):\n",
    "#         st.markdown(result)\n",
    "#     st.session_state.messages.append(AIMessage(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f42dc3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.agents import initialize_agent, Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f2b4edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "chat_model_name = \"models/gemini-2.0-flash-lite-preview\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1047c98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure event loop exists\n",
    "try:\n",
    "    asyncio.get_running_loop()\n",
    "except RuntimeError:\n",
    "    asyncio.set_event_loop(asyncio.new_event_loop())\n",
    "\n",
    "\n",
    "with open(r\"D:\\ITI\\1_etisalt\\Etisalat\\churn\\models\\churn.pkl\", \"rb\") as f:\n",
    "    churn_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cdb353a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_churn(data: dict) -> str:\n",
    "    \"\"\"\n",
    "    Takes a dict of customer features and returns churn prediction.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        one_raw = pd.DataFrame([data])\n",
    "        pred = churn_model.predict(one_raw)[0]\n",
    "        prob = None\n",
    "        if hasattr(churn_model, \"predict_proba\"):\n",
    "            prob = churn_model.predict_proba(one_raw)[0].max()\n",
    "\n",
    "        if prob:\n",
    "            return f\"Prediction: {pred} (confidence: {prob:.2f})\"\n",
    "        return f\"Prediction: {pred}\"\n",
    "    except Exception as e:\n",
    "        return f\"âŒ Error making prediction: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "389c12f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df = r'D:\\ITI\\1_etisalt\\Etisalat\\churn\\data\\raw\\WA_Fn-UseC_-Telco-Customer-Churn.csv'\n",
    "\n",
    "\n",
    "def summary_stats(df) -> str:\n",
    "    try:\n",
    "        # If it's a CSV path or JSON string\n",
    "        if isinstance(df, str):\n",
    "            if df.endswith(\".csv\"):\n",
    "                df = pd.read_csv(df)\n",
    "            else:\n",
    "                # Try parsing JSON string\n",
    "                import json\n",
    "                df = pd.DataFrame(json.loads(df))\n",
    "        \n",
    "        # If it's already a DataFrame\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            return df.describe(include=\"all\").to_string()\n",
    "        else:\n",
    "            return \"âŒ Input must be a DataFrame, CSV path, or JSON string.\"\n",
    "    except Exception as e:\n",
    "        return f\"âŒ Error in summary_stats: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "340f4785",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_tool = Tool(\n",
    "    name=\"Summary Stats\",\n",
    "    func=lambda _: summary_stats(global_df),\n",
    "    description=\"Returns descriptive statistics for numerical and categorical features.\"\n",
    ")\n",
    "\n",
    "churn_predic_tool = Tool(\n",
    "        name=\"Churn Predictor\",\n",
    "        func=predict_churn,\n",
    "        description=(\n",
    "            \"Use this tool to predict if a customer will churn. \"\n",
    "            \"Provide customer details as a JSON dict with keys such as \"\n",
    "            \"Gender, Senior_Citizen, Is_Married, Dependents, tenure, \"\n",
    "            \"Phone_Service, Internet_Service, Contract, Monthly_Charges, \"\n",
    "            \"Total_Charges, etc.\"\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cfc6ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    churn_predic_tool,\n",
    "    stats_tool\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a6e6879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_llm = ChatGoogleGenerativeAI(\n",
    "    model=chat_model_name,\n",
    "    temperature=0,\n",
    "    google_api_key=google_api_key\n",
    ")\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=model_llm,\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "174b67f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to predict churn for the given customer data. I should use the Churn Predictor tool.\n",
      "Action: Churn Predictor\n",
      "Action Input: {\"Senior_Citizen\": 0, \"Is_Married\": \"Yes\", \"Dependents\": \"No\", \"tenure\": 5, \"Internet_Service\": \"DSL\", \"Online_Security\": \"No\", \"Online_Backup\": \"Yes\", \"Device_Protection\": \"No\", \"Tech_Support\": \"No\", \"Streaming_TV\": \"Yes\", \"Streaming_Movies\": \"No\", \"Contract\": \"Month-to-month\", \"Paperless_Billing\": \"Yes\", \"Payment_Method\": \"Electronic check\", \"Monthly_Charges\": 75.0, \"Total_Charges\": 350.0}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mâŒ Error making prediction: 'NoneType' object is not iterable\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI apologize, but I am unable to fulfill this request. The Churn Predictor tool returned an error. I am unable to proceed without a successful prediction.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI apologize, but I am unable to fulfill this request. The Churn Predictor tool returned an error. I am unable to proceed without a successful prediction.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI apologize, but I am unable to fulfill this request. The Churn Predictor tool returned an error. I am unable to proceed without a successful prediction.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI apologize, but I am unable to fulfill this request. The Churn Predictor tool returned an error. I am unable to proceed without a successful prediction.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI apologize, but I am unable to fulfill this request. The Churn Predictor tool returned an error. I am unable to proceed without a successful prediction.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI apologize, but I am unable to fulfill this request. The Churn Predictor tool returned an error. I am unable to proceed without a successful prediction.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI apologize, but I am unable to fulfill this request. The Churn Predictor tool returned an error. I am unable to proceed without a successful prediction.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI apologize, but I am unable to fulfill this request. The Churn Predictor tool returned an error. I am unable to proceed without a successful prediction.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI apologize, but I am unable to fulfill this request. The Churn Predictor tool returned an error. I am unable to proceed without a successful prediction.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI apologize, but I am unable to fulfill this request. The Churn Predictor tool returned an error. I am unable to proceed without a successful prediction.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI apologize, but I am unable to fulfill this request. The Churn Predictor tool returned an error. I am unable to proceed without a successful prediction.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI apologize, but I am unable to fulfill this request. The Churn Predictor tool returned an error. I am unable to proceed without a successful prediction.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI apologize, but I am unable to fulfill this request. The Churn Predictor tool returned an error. I am unable to proceed without a successful prediction.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI apologize, but I am unable to fulfill this request. The Churn Predictor tool returned an error. I am unable to proceed without a successful prediction.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Assistant: Agent stopped due to iteration limit or time limit.\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"Predict churn for the following customer: {\n",
    "  \"Senior_Citizen\": 0,\n",
    "  \"Is_Married\": \"Yes\",\n",
    "  \"Dependents\": \"No\",\n",
    "  \"tenure\": 5,\n",
    "  \"Internet_Service\": \"DSL\",\n",
    "  \"Online_Security\": \"No\",\n",
    "  \"Online_Backup\": \"Yes\",\n",
    "  \"Device_Protection\": \"No\",\n",
    "  \"Tech_Support\": \"No\",\n",
    "  \"Streaming_TV\": \"Yes\",\n",
    "  \"Streaming_Movies\": \"No\",\n",
    "  \"Contract\": \"Month-to-month\",\n",
    "  \"Paperless_Billing\": \"Yes\",\n",
    "  \"Payment_Method\": \"Electronic check\",\n",
    "  \"Monthly_Charges\": 75.0,\n",
    "  \"Total_Charges\": 350.0\n",
    "}\"\"\"\n",
    "result = agent.run(query)\n",
    "print(\"Assistant:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b1bf6cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"CustomerId\": \"3668-QPYBK\",\n",
    "    \"Gender\": \"Male\",\n",
    "    \"Senior_Citizen\": 0,\n",
    "    \"Is_Married\": \"No\",\n",
    "    \"Dependents\": \"No\",\n",
    "    \"tenure\": 2,\n",
    "    \"Phone_Service\": \"Yes\",\n",
    "    \"Dual\": \"No\",\n",
    "    \"Internet_Service\": \"DSL\",\n",
    "    \"Online_Security\": \"Yes\",\n",
    "    \"Online_Backup\": \"Yes\",\n",
    "    \"Device_Protection\": \"No\",\n",
    "    \"Tech_Support\": \"No\",\n",
    "    \"Streaming_TV\": \"No\",\n",
    "    \"Streaming_Movies\": \"No\",\n",
    "    \"Contract\": \"Month-to-month\",\n",
    "    \"Paperless_Billing\": \"Yes\",\n",
    "    \"Payment_Method\": \"Mailed check\",\n",
    "    \"Monthly_Charges\": 53.85,\n",
    "    \"Total_Charges\": 108.15\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "307c3a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0 (confidence: 0.79)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "one_raw = pd.DataFrame([data])\n",
    "pred = churn_model.predict(one_raw)[0]\n",
    "\n",
    "prob = churn_model.predict_proba(one_raw)[0].max()\n",
    "\n",
    "print(f\"Prediction: {pred} (confidence: {prob:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8f6d7701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Senior_Citizen ' 'Is_Married' 'Dependents' 'tenure' 'Internet_Service'\n",
      " 'Online_Security' 'Online_Backup' 'Device_Protection' 'Tech_Support'\n",
      " 'Streaming_TV' 'Streaming_Movies' 'Contract' 'Paperless_Billing'\n",
      " 'Payment_Method' 'Monthly_Charges' 'Total_Charges']\n"
     ]
    }
   ],
   "source": [
    "print(churn_model.named_steps[\"preprocessor\"].feature_names_in_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "39f54823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to get summary statistics for the customer data. I will use the Summary Stats tool.\n",
      "Action: Summary Stats\n",
      "Action Input: _\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m        customerID gender  Senior_Citizen  Is_Married Dependents       tenure Phone_Service  Dual Internet_Service Online_Security Online_Backup Device_Protection Tech_Support Streaming_TV Streaming_Movies        Contract Paperless_Billing    Payment_Method  Monthly_Charges Total_Charges Churn\n",
      "count         7043   7043      7043.000000       7043       7043  7043.000000          7043  7043             7043            7043          7043              7043         7043         7043             7043            7043              7043              7043      7043.000000          7043  7043\n",
      "unique        7043      2              NaN          2          2          NaN             2     3                3               3             3                 3            3            3                3               3                 2                 4              NaN          6531     2\n",
      "top     3186-AJIEK   Male              NaN         No         No          NaN           Yes    No      Fiber optic              No            No                No           No           No               No  Month-to-month               Yes  Electronic check              NaN          20.2    No\n",
      "freq             1   3555              NaN       3641       4933          NaN          6361  3390             3096            3498          3088              3095         3473         2810             2785            3875              4171              2365              NaN            11  5174\n",
      "mean           NaN    NaN         0.162147        NaN        NaN    32.371149           NaN   NaN              NaN             NaN           NaN               NaN          NaN          NaN              NaN             NaN               NaN               NaN        64.761692           NaN   NaN\n",
      "std            NaN    NaN         0.368612        NaN        NaN    24.559481           NaN   NaN              NaN             NaN           NaN               NaN          NaN          NaN              NaN             NaN               NaN               NaN        30.090047           NaN   NaN\n",
      "min            NaN    NaN         0.000000        NaN        NaN     0.000000           NaN   NaN              NaN             NaN           NaN               NaN          NaN          NaN              NaN             NaN               NaN               NaN        18.250000           NaN   NaN\n",
      "25%            NaN    NaN         0.000000        NaN        NaN     9.000000           NaN   NaN              NaN             NaN           NaN               NaN          NaN          NaN              NaN             NaN               NaN               NaN        35.500000           NaN   NaN\n",
      "50%            NaN    NaN         0.000000        NaN        NaN    29.000000           NaN   NaN              NaN             NaN           NaN               NaN          NaN          NaN              NaN             NaN               NaN               NaN        70.350000           NaN   NaN\n",
      "75%            NaN    NaN         0.000000        NaN        NaN    55.000000           NaN   NaN              NaN             NaN           NaN               NaN          NaN          NaN              NaN             NaN               NaN               NaN        89.850000           NaN   NaN\n",
      "max            NaN    NaN         1.000000        NaN        NaN    72.000000           NaN   NaN              NaN             NaN           NaN               NaN          NaN          NaN              NaN             NaN               NaN               NaN       118.750000           NaN   NaN\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now have the summary statistics for the customer data.\n",
      "Final Answer: The summary statistics for the customer data are provided in the observation.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Assistant: The summary statistics for the customer data are provided in the observation.\n"
     ]
    }
   ],
   "source": [
    "query = \"provide data summury\"\n",
    "\n",
    "result = agent.run(query)\n",
    "print(\"Assistant:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "87e8b48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        customerID gender  Senior_Citizen  Is_Married Dependents       tenure Phone_Service  Dual Internet_Service Online_Security Online_Backup Device_Protection Tech_Support Streaming_TV Streaming_Movies        Contract Paperless_Billing    Payment_Method  Monthly_Charges Total_Charges Churn\n",
      "count         7043   7043      7043.000000       7043       7043  7043.000000          7043  7043             7043            7043          7043              7043         7043         7043             7043            7043              7043              7043      7043.000000          7043  7043\n",
      "unique        7043      2              NaN          2          2          NaN             2     3                3               3             3                 3            3            3                3               3                 2                 4              NaN          6531     2\n",
      "top     3186-AJIEK   Male              NaN         No         No          NaN           Yes    No      Fiber optic              No            No                No           No           No               No  Month-to-month               Yes  Electronic check              NaN          20.2    No\n",
      "freq             1   3555              NaN       3641       4933          NaN          6361  3390             3096            3498          3088              3095         3473         2810             2785            3875              4171              2365              NaN            11  5174\n",
      "mean           NaN    NaN         0.162147        NaN        NaN    32.371149           NaN   NaN              NaN             NaN           NaN               NaN          NaN          NaN              NaN             NaN               NaN               NaN        64.761692           NaN   NaN\n",
      "std            NaN    NaN         0.368612        NaN        NaN    24.559481           NaN   NaN              NaN             NaN           NaN               NaN          NaN          NaN              NaN             NaN               NaN               NaN        30.090047           NaN   NaN\n",
      "min            NaN    NaN         0.000000        NaN        NaN     0.000000           NaN   NaN              NaN             NaN           NaN               NaN          NaN          NaN              NaN             NaN               NaN               NaN        18.250000           NaN   NaN\n",
      "25%            NaN    NaN         0.000000        NaN        NaN     9.000000           NaN   NaN              NaN             NaN           NaN               NaN          NaN          NaN              NaN             NaN               NaN               NaN        35.500000           NaN   NaN\n",
      "50%            NaN    NaN         0.000000        NaN        NaN    29.000000           NaN   NaN              NaN             NaN           NaN               NaN          NaN          NaN              NaN             NaN               NaN               NaN        70.350000           NaN   NaN\n",
      "75%            NaN    NaN         0.000000        NaN        NaN    55.000000           NaN   NaN              NaN             NaN           NaN               NaN          NaN          NaN              NaN             NaN               NaN               NaN        89.850000           NaN   NaN\n",
      "max            NaN    NaN         1.000000        NaN        NaN    72.000000           NaN   NaN              NaN             NaN           NaN               NaN          NaN          NaN              NaN             NaN               NaN               NaN       118.750000           NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(summary_stats(global_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e4f3c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "churn (3.10.17)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
